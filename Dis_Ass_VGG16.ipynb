{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyMriui4t63nYTCIP2uF6dkS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"DS1gWrZ-mJsO","executionInfo":{"status":"ok","timestamp":1747041978539,"user_tz":-60,"elapsed":115117,"user":{"displayName":"Ajayesh Saini","userId":"13319741441885932090"}},"outputId":"e093ab8d-10e2-4c6d-a2b1-c66b1b0639fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n","Collecting torch==2.0.1\n","  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp311-cp311-linux_x86_64.whl (2267.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision==0.15.2\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp311-cp311-linux_x86_64.whl (6.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchaudio==2.0.2\n","  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.0.2%2Bcu118-cp311-cp311-linux_x86_64.whl (4.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting numpy==1.24.4\n","  Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.18.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (4.13.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.1.6)\n","Collecting triton==2.0.0 (from torch==2.0.1)\n","  Downloading https://download.pytorch.org/whl/triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (2.32.3)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (11.2.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1) (3.31.6)\n","Collecting lit (from triton==2.0.0->torch==2.0.1)\n","  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (2025.4.26)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n","Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lit, numpy, triton, torch, torchvision, torchaudio\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.2.0\n","    Uninstalling triton-3.2.0:\n","      Successfully uninstalled triton-3.2.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.6.0+cu124\n","    Uninstalling torch-2.6.0+cu124:\n","      Successfully uninstalled torch-2.6.0+cu124\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.21.0+cu124\n","    Uninstalling torchvision-0.21.0+cu124:\n","      Successfully uninstalled torchvision-0.21.0+cu124\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.6.0+cu124\n","    Uninstalling torchaudio-2.6.0+cu124:\n","      Successfully uninstalled torchaudio-2.6.0+cu124\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n","treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n","jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n","pymc 5.22.0 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\n","tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.4 which is incompatible.\n","blosc2 3.3.2 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed lit-18.1.8 numpy-1.24.4 torch-2.0.1+cu118 torchaudio-2.0.2+cu118 torchvision-0.15.2+cu118 triton-2.0.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"5dfa2bcf70db4c8391788770da15f5e9"}},"metadata":{}}],"source":["!pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 numpy==1.24.4 --extra-index-url https://download.pytorch.org/whl/cu118"]},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import os\n","from google.colab import drive\n","import sys\n","import torchvision.datasets as datasets\n","import numpy as np\n","import pickle\n","from PIL import Image\n","from torchvision.datasets import CIFAR10,CIFAR100\n","from google.colab import files\n","import zipfile\n","import os\n","import shutil"],"metadata":{"id":"tRX7I5CYmgtn","executionInfo":{"status":"ok","timestamp":1747042123640,"user_tz":-60,"elapsed":4105,"user":{"displayName":"Ajayesh Saini","userId":"13319741441885932090"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["!pip install torch_pruning\n","!pip install torchinfo\n","!pip install thop"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MyIEd21kmhM0","executionInfo":{"status":"ok","timestamp":1747042131172,"user_tz":-60,"elapsed":7531,"user":{"displayName":"Ajayesh Saini","userId":"13319741441885932090"}},"outputId":"78cba203-d07d-4ae8-d4df-956eed628b25"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch_pruning\n","  Downloading torch_pruning-1.5.2-py3-none-any.whl.metadata (31 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torch_pruning) (2.0.1+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_pruning) (1.24.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torch_pruning) (3.18.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->torch_pruning) (4.13.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->torch_pruning) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torch_pruning) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torch_pruning) (3.1.6)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch_pruning) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch->torch_pruning) (3.31.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch->torch_pruning) (18.1.8)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torch_pruning) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->torch_pruning) (1.3.0)\n","Downloading torch_pruning-1.5.2-py3-none-any.whl (64 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch_pruning\n","Successfully installed torch_pruning-1.5.2\n","Collecting torchinfo\n","  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n","Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-1.8.0\n","Collecting thop\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from thop) (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.18.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->thop) (4.13.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->thop) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.1.6)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch->thop) (3.31.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch->thop) (18.1.8)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->thop) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->thop) (1.3.0)\n","Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Installing collected packages: thop\n","Successfully installed thop-0.1.1.post2209072238\n"]}]},{"cell_type":"code","source":["drive.mount('/content/drive')\n","workspace_path = \"/content/drive/MyDrive/DeepLearningCW\"\n","os.makedirs(workspace_path, exist_ok=True)\n","%cd {workspace_path}\n","print(f\"Working inside: {workspace_path}\")\n","%cd /content/drive/MyDrive/DeepLearningCW/Model-LEGO\n","\n","sys.path.append(os.getcwd())\n","print(\"Current Working Directory:\", os.getcwd())\n","print(\"Python Path:\", sys.path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wIbIsEqFmmXL","executionInfo":{"status":"ok","timestamp":1747042149780,"user_tz":-60,"elapsed":16489,"user":{"displayName":"Ajayesh Saini","userId":"13319741441885932090"}},"outputId":"7a9da510-3c2f-488b-b135-17ade3e2f456"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/DeepLearningCW\n","Working inside: /content/drive/MyDrive/DeepLearningCW\n","/content/drive/MyDrive/DeepLearningCW/Model-LEGO\n","Current Working Directory: /content/drive/MyDrive/DeepLearningCW/Model-LEGO\n","Python Path: ['/content', '/env/python', '/usr/lib/python311.zip', '/usr/lib/python3.11', '/usr/lib/python3.11/lib-dynload', '', '/usr/local/lib/python3.11/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.11/dist-packages/IPython/extensions', '/root/.ipython', '/content/drive/MyDrive/DeepLearningCW/Model-LEGO']\n"]}]},{"cell_type":"markdown","source":["#Unzip CIFAR10"],"metadata":{"id":"SuSey8UDmw-9"}},{"cell_type":"code","source":["\n","\n","\n","zip_path = \"/content/cifar10_images.zip\"\n","\n","\n","extract_folder = \"cifar10_images.zip\".replace(\".zip\", \"\")\n","extract_path = f\"/content/{extract_folder}\"\n","\n","\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract_path)\n","\n","print(\" Upload and extraction complete.\")\n","print(\"Extracted to:\", extract_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SOJJau20m0Xx","executionInfo":{"status":"ok","timestamp":1746782030156,"user_tz":-60,"elapsed":5445,"user":{"displayName":"Ajayesh Saini","userId":"13319741441885932090"}},"outputId":"321f357a-0c14-4e60-9b3d-218a8e9703b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" Upload and extraction complete.\n","Extracted to: /content/cifar10_images\n"]}]},{"cell_type":"markdown","source":["# Unzip CIFAR100"],"metadata":{"id":"zqOd6TPBm7hy"}},{"cell_type":"code","source":["zip_path = \"/content/cifar100_images.zip\"\n","\n","\n","extract_folder = \"cifar100_images.zip\".replace(\".zip\", \"\")\n","extract_path = f\"/content/{extract_folder}\"\n","\n","\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract_path)\n","\n","print(\" Upload and extraction complete.\")\n","print(\"Extracted to:\", extract_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K3SgezIpm7K3","executionInfo":{"status":"ok","timestamp":1746782041057,"user_tz":-60,"elapsed":5330,"user":{"displayName":"Ajayesh Saini","userId":"13319741441885932090"}},"outputId":"3ce76879-b48e-450c-9c4c-2493b87b5049"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" Upload and extraction complete.\n","Extracted to: /content/cifar100_images\n"]}]},{"cell_type":"markdown","source":["# Unzip tinyimagenet"],"metadata":{"id":"n6Hzt1IGnK41"}},{"cell_type":"code","source":["zip_path = \"/content/tiny_imagenet_images.zip\"\n","\n","extract_folder = \"tiny_imagenet_images.zip\".replace(\".zip\", \"\")\n","extract_path = f\"/content/{extract_folder}\"\n","\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract_path)\n","\n","print(\" Upload and extraction complete.\")\n","print(\"Extracted to:\", extract_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HVzAOCelnNnk","executionInfo":{"status":"ok","timestamp":1747042251515,"user_tz":-60,"elapsed":12056,"user":{"displayName":"Ajayesh Saini","userId":"13319741441885932090"}},"outputId":"397ec1c6-7212-4bfa-95ae-1a5e252ef15d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":[" Upload and extraction complete.\n","Extracted to: /content/tiny_imagenet_images\n"]}]},{"cell_type":"markdown","source":["# Make subset of dataset"],"metadata":{"id":"qywyolbCoQC5"}},{"cell_type":"code","source":["\n","\n","def filter_selected_classes(source_dir, target_dir, class_indices):\n","\n","    os.makedirs(target_dir, exist_ok=True)\n","\n","\n","    class_folders = sorted([d for d in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, d))])\n","\n","    class_indices = list(class_indices)\n","\n","\n","    selected_classes = [class_folders[i] for i in class_indices if i < len(class_folders)]\n","\n","    for class_name in selected_classes:\n","        src_path = os.path.join(source_dir, class_name)\n","        dst_path = os.path.join(target_dir, class_name)\n","        shutil.copytree(src_path, dst_path)\n","        print(f\"Copied: {class_name}\")\n"],"metadata":{"id":"IWcO1P8NoTss","executionInfo":{"status":"ok","timestamp":1747042276342,"user_tz":-60,"elapsed":4,"user":{"displayName":"Ajayesh Saini","userId":"13319741441885932090"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["filter_selected_classes(\n","    source_dir=\"/content/tiny_imagenet_images/saved_datasets/tiny_imagenet_images/val\",\n","    target_dir=\"/content/tiny_imagenet_subset/test_0_69\",\n","    class_indices=range(0, 70)\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"MsCgjZnAoe-p","executionInfo":{"status":"ok","timestamp":1744539630875,"user_tz":-60,"elapsed":322,"user":{"displayName":"Ajayesh Saini","userId":"13319741441885932090"}},"outputId":"375a64ad-fecc-4da6-868d-917426054cea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Copied: n01443537\n","Copied: n01629819\n","Copied: n01641577\n","Copied: n01644900\n","Copied: n01698640\n","Copied: n01742172\n","Copied: n01768244\n","Copied: n01770393\n","Copied: n01774384\n","Copied: n01774750\n","Copied: n01784675\n","Copied: n01855672\n","Copied: n01882714\n","Copied: n01910747\n","Copied: n01917289\n","Copied: n01944390\n","Copied: n01945685\n","Copied: n01950731\n","Copied: n01983481\n","Copied: n01984695\n","Copied: n02002724\n","Copied: n02056570\n","Copied: n02058221\n","Copied: n02074367\n","Copied: n02085620\n","Copied: n02094433\n","Copied: n02099601\n","Copied: n02099712\n","Copied: n02106662\n","Copied: n02113799\n","Copied: n02123045\n","Copied: n02123394\n","Copied: n02124075\n","Copied: n02125311\n","Copied: n02129165\n","Copied: n02132136\n","Copied: n02165456\n","Copied: n02190166\n","Copied: n02206856\n","Copied: n02226429\n","Copied: n02231487\n","Copied: n02233338\n","Copied: n02236044\n","Copied: n02268443\n","Copied: n02279972\n","Copied: n02281406\n","Copied: n02321529\n","Copied: n02364673\n","Copied: n02395406\n","Copied: n02403003\n","Copied: n02410509\n","Copied: n02415577\n","Copied: n02423022\n","Copied: n02437312\n","Copied: n02480495\n","Copied: n02481823\n","Copied: n02486410\n","Copied: n02504458\n","Copied: n02509815\n","Copied: n02666196\n","Copied: n02669723\n","Copied: n02699494\n","Copied: n02730930\n","Copied: n02769748\n","Copied: n02788148\n","Copied: n02791270\n","Copied: n02793495\n","Copied: n02795169\n","Copied: n02802426\n","Copied: n02808440\n"]}]},{"cell_type":"markdown","source":["# Combine Dataset"],"metadata":{"id":"PAcTy1Iyrx_5"}},{"cell_type":"code","source":["import os\n","import shutil\n","from glob import glob\n","\n","def merge_datasets(dataset1_path, dataset2_path, save_path):\n","    os.makedirs(save_path, exist_ok=True)\n","\n","    # Sort class folders alphabetically\n","    dataset1_classes = sorted(os.listdir(dataset1_path))\n","    dataset2_classes = sorted(os.listdir(dataset2_path))\n","\n","    print(f\"Found {len(dataset1_classes)} classes in Dataset 1 and {len(dataset2_classes)} in Dataset 2.\")\n","\n","    def copy_dataset(source_path, classes, offset):\n","        for i, class_name in enumerate(classes):\n","            label = i + offset\n","            src_dir = os.path.join(source_path, class_name)\n","            dst_dir = os.path.join(save_path, f\"{label:03d}\")\n","            os.makedirs(dst_dir, exist_ok=True)\n","\n","            for img_path in glob(os.path.join(src_dir, '*')):\n","                shutil.copy(img_path, dst_dir)\n","            print(f\"Copied class '{class_name}' as '{label:03d}'\")\n","\n","    print(\"Copying Dataset 1...\")\n","    copy_dataset(dataset1_path, dataset1_classes, offset=0)\n","\n","    print(\"Copying Dataset 2...\")\n","    copy_dataset(dataset2_path, dataset2_classes, offset=len(dataset1_classes))\n","\n","    print(f\" Merge Complete! Combined dataset saved at: {save_path}\")\n"],"metadata":{"id":"jp0WeKjqqrdc","executionInfo":{"status":"ok","timestamp":1747042279110,"user_tz":-60,"elapsed":3,"user":{"displayName":"Ajayesh Saini","userId":"13319741441885932090"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# Dissassembly"],"metadata":{"id":"3wpKO8OZr-q2"}},{"cell_type":"code","source":["!python -m core.sample_select \\\n","  --model_name 'vgg16' \\\n","  --data_name 'tiny-imagenet' \\\n","  --num_classes 200 \\\n","  --model_path \"/content/drive/MyDrive/DeepLearningCW/Model-LEGO/saved_models/VGG16_tinyimagenet_seed123.pth\" \\\n","  --data_dir \"/content/tiny_imagenet_images/saved_datasets/tiny_imagenet_images/train\" \\\n","  --save_dir \"/content/samples_tiny_imagenet_images_seed123\" \\\n","  --num_samples 5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PN4g_olur-Wy","executionInfo":{"status":"ok","timestamp":1747047792977,"user_tz":-60,"elapsed":23205,"user":{"displayName":"Ajayesh Saini","userId":"13319741441885932090"}},"outputId":"bfaf46b2-a347-4da6-ab56-2266e8199a15"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["--------------------------------------------------\n","TRAIN ON: cuda\n","MODEL PATH: /content/drive/MyDrive/DeepLearningCW/Model-LEGO/saved_models/VGG16_tinyimagenet_seed123.pth\n","DATA PATH: /content/tiny_imagenet_images/saved_datasets/tiny_imagenet_images/train\n","RESULT PATH: /content/samples_tiny_imagenet_images_seed123\n","--------------------------------------------------\n","--------------------------------------------------\n","LOAD MODEL: vgg16\n","NUM CLASSES: 200\n","--------------------------------------------------\n","--------------------------------------------------\n","DATA PATH: /content/tiny_imagenet_images/saved_datasets/tiny_imagenet_images/train\n","DATA NAME: tiny-imagenet \t|\tDATA TYPE: test\n","--------------------------------------------------\n","100% 391/391 [00:19<00:00, 20.04it/s]\n","tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000]])\n","tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n","        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n","        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n","        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n","        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n","        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n","        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n","        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n","        5, 5, 5, 5, 5, 5, 5, 5])\n","['n01443537', 'n01629819', 'n01641577', 'n01644900', 'n01698640', 'n01742172', 'n01768244', 'n01770393', 'n01774384', 'n01774750', 'n01784675', 'n01855672', 'n01882714', 'n01910747', 'n01917289', 'n01944390', 'n01945685', 'n01950731', 'n01983481', 'n01984695', 'n02002724', 'n02056570', 'n02058221', 'n02074367', 'n02085620', 'n02094433', 'n02099601', 'n02099712', 'n02106662', 'n02113799', 'n02123045', 'n02123394', 'n02124075', 'n02125311', 'n02129165', 'n02132136', 'n02165456', 'n02190166', 'n02206856', 'n02226429', 'n02231487', 'n02233338', 'n02236044', 'n02268443', 'n02279972', 'n02281406', 'n02321529', 'n02364673', 'n02395406', 'n02403003', 'n02410509', 'n02415577', 'n02423022', 'n02437312', 'n02480495', 'n02481823', 'n02486410', 'n02504458', 'n02509815', 'n02666196', 'n02669723', 'n02699494', 'n02730930', 'n02769748', 'n02788148', 'n02791270', 'n02793495', 'n02795169', 'n02802426', 'n02808440', 'n02814533', 'n02814860', 'n02815834', 'n02823428', 'n02837789', 'n02841315', 'n02843684', 'n02883205', 'n02892201', 'n02906734', 'n02909870', 'n02917067', 'n02927161', 'n02948072', 'n02950826', 'n02963159', 'n02977058', 'n02988304', 'n02999410', 'n03014705', 'n03026506', 'n03042490', 'n03085013', 'n03089624', 'n03100240', 'n03126707', 'n03160309', 'n03179701', 'n03201208', 'n03250847', 'n03255030', 'n03355925', 'n03388043', 'n03393912', 'n03400231', 'n03404251', 'n03424325', 'n03444034', 'n03447447', 'n03544143', 'n03584254', 'n03599486', 'n03617480', 'n03637318', 'n03649909', 'n03662601', 'n03670208', 'n03706229', 'n03733131', 'n03763968', 'n03770439', 'n03796401', 'n03804744', 'n03814639', 'n03837869', 'n03838899', 'n03854065', 'n03891332', 'n03902125', 'n03930313', 'n03937543', 'n03970156', 'n03976657', 'n03977966', 'n03980874', 'n03983396', 'n03992509', 'n04008634', 'n04023962', 'n04067472', 'n04070727', 'n04074963', 'n04099969', 'n04118538', 'n04133789', 'n04146614', 'n04149813', 'n04179913', 'n04251144', 'n04254777', 'n04259630', 'n04265275', 'n04275548', 'n04285008', 'n04311004', 'n04328186', 'n04356056', 'n04366367', 'n04371430', 'n04376876', 'n04398044', 'n04399382', 'n04417672', 'n04456115', 'n04465501', 'n04486054', 'n04487081', 'n04501370', 'n04507155', 'n04532106', 'n04532670', 'n04540053', 'n04560804', 'n04562935', 'n04596742', 'n04597913', 'n06596364', 'n07579787', 'n07583066', 'n07614500', 'n07615774', 'n07695742', 'n07711569', 'n07715103', 'n07720875', 'n07734744', 'n07747607', 'n07749582', 'n07753592', 'n07768694', 'n07871810', 'n07873807', 'n07875152', 'n07920052', 'n09193705', 'n09246464', 'n09256479', 'n09332890', 'n09428293', 'n12267677']\n","100% 5/5 [00:00<00:00, 5944.31it/s]\n","100% 5/5 [00:00<00:00, 9291.77it/s]\n","100% 5/5 [00:00<00:00, 10443.98it/s]\n","100% 5/5 [00:00<00:00, 10849.21it/s]\n","100% 5/5 [00:00<00:00, 10438.79it/s]\n","100% 5/5 [00:00<00:00, 10776.73it/s]\n","100% 5/5 [00:00<00:00, 10376.80it/s]\n","100% 5/5 [00:00<00:00, 10275.12it/s]\n","100% 5/5 [00:00<00:00, 11323.71it/s]\n","100% 5/5 [00:00<00:00, 10356.31it/s]\n","100% 5/5 [00:00<00:00, 10480.52it/s]\n","100% 5/5 [00:00<00:00, 11190.78it/s]\n","100% 5/5 [00:00<00:00, 9873.60it/s]\n","100% 5/5 [00:00<00:00, 11037.64it/s]\n","100% 5/5 [00:00<00:00, 10215.06it/s]\n","100% 5/5 [00:00<00:00, 10661.68it/s]\n","100% 5/5 [00:00<00:00, 11299.31it/s]\n","100% 5/5 [00:00<00:00, 10496.26it/s]\n","100% 5/5 [00:00<00:00, 10565.00it/s]\n","100% 5/5 [00:00<00:00, 10749.11it/s]\n","100% 5/5 [00:00<00:00, 8901.32it/s]\n","100% 5/5 [00:00<00:00, 11072.61it/s]\n","100% 5/5 [00:00<00:00, 10928.36it/s]\n","100% 5/5 [00:00<00:00, 10376.80it/s]\n","100% 5/5 [00:00<00:00, 10877.34it/s]\n","100% 5/5 [00:00<00:00, 9650.95it/s]\n","100% 5/5 [00:00<00:00, 10776.73it/s]\n","100% 5/5 [00:00<00:00, 10721.64it/s]\n","100% 5/5 [00:00<00:00, 10175.41it/s]\n","100% 5/5 [00:00<00:00, 10470.05it/s]\n","100% 5/5 [00:00<00:00, 10956.91it/s]\n","100% 5/5 [00:00<00:00, 9855.04it/s]\n","100% 5/5 [00:00<00:00, 10721.64it/s]\n","100% 5/5 [00:00<00:00, 9383.23it/s]\n","100% 5/5 [00:00<00:00, 10160.62it/s]\n","100% 5/5 [00:00<00:00, 10962.63it/s]\n","100% 5/5 [00:00<00:00, 10285.20it/s]\n","100% 5/5 [00:00<00:00, 11131.38it/s]\n","100% 5/5 [00:00<00:00, 10554.36it/s]\n","100% 5/5 [00:00<00:00, 10454.40it/s]\n","100% 5/5 [00:00<00:00, 11190.78it/s]\n","100% 5/5 [00:00<00:00, 10092.17it/s]\n","100% 5/5 [00:00<00:00, 10951.19it/s]\n","100% 5/5 [00:00<00:00, 10580.99it/s]\n","100% 5/5 [00:00<00:00, 9695.57it/s]\n","100% 5/5 [00:00<00:00, 11190.78it/s]\n","100% 5/5 [00:00<00:00, 9145.89it/s]\n","100% 5/5 [00:00<00:00, 10280.16it/s]\n","100% 5/5 [00:00<00:00, 10945.47it/s]\n","100% 5/5 [00:00<00:00, 10538.45it/s]\n","100% 5/5 [00:00<00:00, 10710.68it/s]\n","100% 5/5 [00:00<00:00, 10623.87it/s]\n","100% 5/5 [00:00<00:00, 9086.45it/s]\n","100% 5/5 [00:00<00:00, 10798.93it/s]\n","100% 5/5 [00:00<00:00, 10997.13it/s]\n","100% 5/5 [00:00<00:00, 10019.84it/s]\n","100% 5/5 [00:00<00:00, 10951.19it/s]\n","100% 5/5 [00:00<00:00, 9836.55it/s]\n","100% 5/5 [00:00<00:00, 8090.86it/s]\n","100% 5/5 [00:00<00:00, 10860.45it/s]\n","100% 5/5 [00:00<00:00, 10613.12it/s]\n","100% 5/5 [00:00<00:00, 9991.20it/s]\n","100% 5/5 [00:00<00:00, 11202.74it/s]\n","100% 5/5 [00:00<00:00, 9370.65it/s]\n","100% 5/5 [00:00<00:00, 11084.31it/s]\n","100% 5/5 [00:00<00:00, 11043.45it/s]\n","100% 5/5 [00:00<00:00, 10387.08it/s]\n","100% 5/5 [00:00<00:00, 11143.21it/s]\n","100% 5/5 [00:00<00:00, 10570.32it/s]\n","100% 5/5 [00:00<00:00, 10491.01it/s]\n","100% 5/5 [00:00<00:00, 10661.68it/s]\n","100% 5/5 [00:00<00:00, 8837.56it/s]\n","100% 5/5 [00:00<00:00, 10710.68it/s]\n","100% 5/5 [00:00<00:00, 11190.78it/s]\n","100% 5/5 [00:00<00:00, 10140.97it/s]\n","100% 5/5 [00:00<00:00, 10962.63it/s]\n","100% 5/5 [00:00<00:00, 10140.97it/s]\n","100% 5/5 [00:00<00:00, 8856.22it/s]\n","100% 5/5 [00:00<00:00, 11113.68it/s]\n","100% 5/5 [00:00<00:00, 10475.28it/s]\n","100% 5/5 [00:00<00:00, 10974.11it/s]\n","100% 5/5 [00:00<00:00, 10922.67it/s]\n","100% 5/5 [00:00<00:00, 9532.51it/s]\n","100% 5/5 [00:00<00:00, 11049.27it/s]\n","100% 5/5 [00:00<00:00, 9078.58it/s]\n","100% 5/5 [00:00<00:00, 10180.35it/s]\n","100% 5/5 [00:00<00:00, 10760.14it/s]\n","100% 5/5 [00:00<00:00, 10771.20it/s]\n","100% 5/5 [00:00<00:00, 10882.99it/s]\n","100% 5/5 [00:00<00:00, 10826.80it/s]\n","100% 5/5 [00:00<00:00, 8916.46it/s]\n","100% 5/5 [00:00<00:00, 10882.99it/s]\n","100% 5/5 [00:00<00:00, 11202.74it/s]\n","100% 5/5 [00:00<00:00, 9763.28it/s]\n","100% 5/5 [00:00<00:00, 11311.50it/s]\n","100% 5/5 [00:00<00:00, 9731.56it/s]\n","100% 5/5 [00:00<00:00, 10782.27it/s]\n","100% 5/5 [00:00<00:00, 11131.38it/s]\n","100% 5/5 [00:00<00:00, 10549.05it/s]\n","100% 5/5 [00:00<00:00, 11031.84it/s]\n","100% 5/5 [00:00<00:00, 10661.68it/s]\n","100% 5/5 [00:00<00:00, 9758.73it/s]\n","100% 5/5 [00:00<00:00, 11184.81it/s]\n","100% 5/5 [00:00<00:00, 9141.90it/s]\n","100% 5/5 [00:00<00:00, 10894.30it/s]\n","100% 5/5 [00:00<00:00, 11084.31it/s]\n","100% 5/5 [00:00<00:00, 10591.68it/s]\n","100% 5/5 [00:00<00:00, 11305.40it/s]\n","100% 5/5 [00:00<00:00, 10145.87it/s]\n","100% 5/5 [00:00<00:00, 9110.13it/s]\n","100% 5/5 [00:00<00:00, 11287.15it/s]\n","100% 5/5 [00:00<00:00, 10549.05it/s]\n","100% 5/5 [00:00<00:00, 10661.68it/s]\n","100% 5/5 [00:00<00:00, 11143.21it/s]\n","100% 5/5 [00:00<00:00, 9957.99it/s]\n","100% 5/5 [00:00<00:00, 11202.74it/s]\n","100% 5/5 [00:00<00:00, 9416.94it/s]\n","100% 5/5 [00:00<00:00, 10491.01it/s]\n","100% 5/5 [00:00<00:00, 11323.71it/s]\n","100% 5/5 [00:00<00:00, 10501.51it/s]\n","100% 5/5 [00:00<00:00, 11178.85it/s]\n","100% 5/5 [00:00<00:00, 10053.46it/s]\n","100% 5/5 [00:00<00:00, 10300.35it/s]\n","100% 5/5 [00:00<00:00, 11125.47it/s]\n","100% 5/5 [00:00<00:00, 10205.12it/s]\n","100% 5/5 [00:00<00:00, 10381.94it/s]\n","100% 5/5 [00:00<00:00, 10939.76it/s]\n","100% 5/5 [00:00<00:00, 9745.13it/s]\n","100% 5/5 [00:00<00:00, 10765.67it/s]\n","100% 5/5 [00:00<00:00, 9271.23it/s]\n","100% 5/5 [00:00<00:00, 10629.25it/s]\n","100% 5/5 [00:00<00:00, 10849.21it/s]\n","100% 5/5 [00:00<00:00, 10387.08it/s]\n","100% 5/5 [00:00<00:00, 11113.68it/s]\n","100% 5/5 [00:00<00:00, 10586.33it/s]\n","100% 5/5 [00:00<00:00, 8594.89it/s]\n","100% 5/5 [00:00<00:00, 11113.68it/s]\n","100% 5/5 [00:00<00:00, 10705.22it/s]\n","100% 5/5 [00:00<00:00, 10215.06it/s]\n","100% 5/5 [00:00<00:00, 10743.61it/s]\n","100% 5/5 [00:00<00:00, 9425.40it/s]\n","100% 5/5 [00:00<00:00, 10787.82it/s]\n","100% 5/5 [00:00<00:00, 10650.85it/s]\n","100% 5/5 [00:00<00:00, 10330.80it/s]\n","100% 5/5 [00:00<00:00, 10623.87it/s]\n","100% 5/5 [00:00<00:00, 11072.61it/s]\n","100% 5/5 [00:00<00:00, 9624.38it/s]\n","100% 5/5 [00:00<00:00, 11002.90it/s]\n","100% 5/5 [00:00<00:00, 9149.88it/s]\n","100% 5/5 [00:00<00:00, 10190.24it/s]\n","100% 5/5 [00:00<00:00, 11220.72it/s]\n","100% 5/5 [00:00<00:00, 10215.06it/s]\n","100% 5/5 [00:00<00:00, 10894.30it/s]\n","100% 5/5 [00:00<00:00, 10672.53it/s]\n","100% 5/5 [00:00<00:00, 8890.00it/s]\n","100% 5/5 [00:00<00:00, 11026.04it/s]\n","100% 5/5 [00:00<00:00, 11190.78it/s]\n","100% 5/5 [00:00<00:00, 9845.78it/s]\n","100% 5/5 [00:00<00:00, 10922.67it/s]\n","100% 5/5 [00:00<00:00, 9818.13it/s]\n","100% 5/5 [00:00<00:00, 10826.80it/s]\n","100% 5/5 [00:00<00:00, 10361.42it/s]\n","100% 5/5 [00:00<00:00, 6171.72it/s]\n","100% 5/5 [00:00<00:00, 9497.97it/s]\n","100% 5/5 [00:00<00:00, 10815.64it/s]\n","100% 5/5 [00:00<00:00, 10782.27it/s]\n","100% 5/5 [00:00<00:00, 9619.96it/s]\n","100% 5/5 [00:00<00:00, 10866.07it/s]\n","100% 5/5 [00:00<00:00, 9185.95it/s]\n","100% 5/5 [00:00<00:00, 10205.12it/s]\n","100% 5/5 [00:00<00:00, 11149.13it/s]\n","100% 5/5 [00:00<00:00, 9991.20it/s]\n","100% 5/5 [00:00<00:00, 11014.45it/s]\n","100% 5/5 [00:00<00:00, 10882.99it/s]\n","100% 5/5 [00:00<00:00, 8830.11it/s]\n","100% 5/5 [00:00<00:00, 11131.38it/s]\n","100% 5/5 [00:00<00:00, 11008.67it/s]\n","100% 5/5 [00:00<00:00, 10533.16it/s]\n","100% 5/5 [00:00<00:00, 11020.24it/s]\n","100% 5/5 [00:00<00:00, 9901.57it/s]\n","100% 5/5 [00:00<00:00, 10667.10it/s]\n","100% 5/5 [00:00<00:00, 10597.03it/s]\n","100% 5/5 [00:00<00:00, 10215.06it/s]\n","100% 5/5 [00:00<00:00, 11166.94it/s]\n","100% 5/5 [00:00<00:00, 10602.39it/s]\n","100% 5/5 [00:00<00:00, 9400.05it/s]\n","100% 5/5 [00:00<00:00, 10997.13it/s]\n","100% 5/5 [00:00<00:00, 8981.38it/s]\n","100% 5/5 [00:00<00:00, 9673.21it/s]\n","100% 5/5 [00:00<00:00, 10629.25it/s]\n","100% 5/5 [00:00<00:00, 10418.04it/s]\n","100% 5/5 [00:00<00:00, 10974.11it/s]\n","100% 5/5 [00:00<00:00, 10629.25it/s]\n","100% 5/5 [00:00<00:00, 10220.04it/s]\n","100% 5/5 [00:00<00:00, 10905.63it/s]\n","100% 5/5 [00:00<00:00, 10522.59it/s]\n","100% 5/5 [00:00<00:00, 10888.64it/s]\n","100% 5/5 [00:00<00:00, 10871.71it/s]\n","100% 5/5 [00:00<00:00, 9425.40it/s]\n","100% 5/5 [00:00<00:00, 11161.00it/s]\n"]}]},{"cell_type":"code","source":["!python -m core.relevant_feature_identifying_modified \\\n","  --model_name 'vgg16' \\\n","  --data_name 'tiny-imagenet' \\\n","  --num_classes 200 \\\n","  --model_path \"./saved_models/VGG16_tinyimagenet_seed123.pth\" \\\n","  --data_dir \"/content/samples_tiny_imagenet_images_seed123\" \\\n","  --save_dir \"./saved_masks/\" \\\n","  --mask_folder \"masks_VGG16_tinyimagenet_seed123.pth\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PGURToYBzgG4","executionInfo":{"status":"ok","timestamp":1747047961300,"user_tz":-60,"elapsed":156674,"user":{"displayName":"Ajayesh Saini","userId":"13319741441885932090"}},"outputId":"a604fbe3-cbdc-4fed-bfb7-dcb99a5e6081"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["--------------------------------------------------\n","TRAIN ON: cuda\n","DATA DIR: /content/samples_tiny_imagenet_images_seed123\n","SAVE DIR: ./saved_masks/\n","--------------------------------------------------\n","--------------------------------------------------\n","LOAD MODEL: vgg16\n","NUM CLASSES: 200\n","--------------------------------------------------\n","--------------------------------------------------\n","DATA PATH: /content/samples_tiny_imagenet_images_seed123\n","DATA NAME: tiny-imagenet \t|\tDATA TYPE: test\n","--------------------------------------------------\n","--------------------------------------------------\n","Model Layers: None\n","Model Modules: [Linear(in_features=4096, out_features=200, bias=True), Linear(in_features=4096, out_features=4096, bias=True), Linear(in_features=2048, out_features=4096, bias=True), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n","Model Modules Length: 16\n","--------------------------------------------------\n","100% 8/8 [01:50<00:00, 13.79s/it]\n","--------------------\n","torch.Size([200, 200])\n","torch.Size([200, 200, 4096])\n","--------------------\n","--------------------\n","torch.Size([200, 4096])\n","torch.Size([200, 4096, 4096])\n","--------------------\n","--------------------\n","torch.Size([200, 4096])\n","torch.Size([200, 4096, 2048])\n","--------------------\n","--------------------\n","torch.Size([200, 2048])\n","torch.Size([200, 512, 512])\n","--------------------\n","--------------------\n","torch.Size([200, 512])\n","torch.Size([200, 512, 512])\n","--------------------\n","--------------------\n","torch.Size([200, 512])\n","torch.Size([200, 512, 512])\n","--------------------\n","--------------------\n","torch.Size([200, 512])\n","torch.Size([200, 512, 512])\n","--------------------\n","--------------------\n","torch.Size([200, 512])\n","torch.Size([200, 512, 512])\n","--------------------\n","--------------------\n","torch.Size([200, 512])\n","torch.Size([200, 512, 256])\n","--------------------\n","--------------------\n","torch.Size([200, 256])\n","torch.Size([200, 256, 256])\n","--------------------\n","--------------------\n","torch.Size([200, 256])\n","torch.Size([200, 256, 256])\n","--------------------\n","--------------------\n","torch.Size([200, 256])\n","torch.Size([200, 256, 128])\n","--------------------\n","--------------------\n","torch.Size([200, 128])\n","torch.Size([200, 128, 128])\n","--------------------\n","--------------------\n","torch.Size([200, 128])\n","torch.Size([200, 128, 64])\n","--------------------\n","--------------------\n","torch.Size([200, 64])\n","torch.Size([200, 64, 64])\n","--------------------\n","--------------------\n","torch.Size([200, 64])\n","torch.Size([200, 64, 3])\n","--------------------\n"]}]},{"cell_type":"code","source":["!python -m core.model_disassemble_modified \\\n","  --model_name 'vgg16' \\\n","  --num_classes 200 \\\n","  --model_path './saved_models/VGG16_tinyimagenet_seed123.pth' \\\n","  --save_dir './saved_disassembled_models' \\\n","  --mask_dir './saved_masks/masks_VGG16_tinyimagenet_seed123.pth' \\\n","  --disa_layers -1 \\\n","  --disa_labels 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 \\\n","  --model_save_name 'VGG16_tinyimagenet_disassembled_seed12_150_199.pth'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8szzkO3q2_Lt","executionInfo":{"status":"ok","timestamp":1747048495611,"user_tz":-60,"elapsed":5125,"user":{"displayName":"Ajayesh Saini","userId":"13319741441885932090"}},"outputId":"8bfbb938-0003-4b8b-9d04-4d28e25177db"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["--------------------------------------------------\n","SAVE DIR: ./saved_disassembled_models\n","--------------------------------------------------\n","--------------------------------------------------\n","LOAD MODEL: vgg16\n","NUM CLASSES: 200\n","--------------------------------------------------\n","--------------------------------------------------\n","Model Layers: None\n","Model Modules: [Linear(in_features=4096, out_features=200, bias=True), Linear(in_features=4096, out_features=4096, bias=True), Linear(in_features=2048, out_features=4096, bias=True), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n","Model Modules Length: 16\n","--------------------------------------------------\n","Disassembling layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n","Disassembling labels: [150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199]\n","===> LAYER 0\n","---> Linear(in_features=4096, out_features=200, bias=True)\n","---> Linear(in_features=3116, out_features=200, bias=True)\n","===> LAYER 1\n","---> Linear(in_features=4096, out_features=3116, bias=True)\n","---> Linear(in_features=2888, out_features=3116, bias=True)\n","===> LAYER 2\n","---> Linear(in_features=2048, out_features=2888, bias=True)\n","---> Linear(in_features=540, out_features=2888, bias=True)\n","===> LAYER 3\n","---> Conv2d(512, 135, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","---> Conv2d(493, 135, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","===> LAYER 4\n","---> Conv2d(512, 493, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","---> Conv2d(481, 493, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","===> LAYER 5\n","---> Conv2d(512, 481, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","---> Conv2d(507, 481, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","===> LAYER 6\n","---> Conv2d(512, 507, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","---> Conv2d(495, 507, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","===> LAYER 7\n","---> Conv2d(512, 495, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","---> Conv2d(497, 495, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","===> LAYER 8\n","---> Conv2d(256, 497, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","---> Conv2d(253, 497, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","===> LAYER 9\n","---> Conv2d(256, 253, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","---> Conv2d(236, 253, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","===> LAYER 10\n","---> Conv2d(256, 236, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","---> Conv2d(233, 236, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","===> LAYER 11\n","---> Conv2d(128, 233, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","---> Conv2d(120, 233, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","===> LAYER 12\n","---> Conv2d(128, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","---> Conv2d(121, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","===> LAYER 13\n","---> Conv2d(64, 121, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","---> Conv2d(64, 121, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","===> LAYER 14\n","---> Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","---> Conv2d(61, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","---> OUTPUT PRUNE: Linear(in_features=3116, out_features=200, bias=True)\n","---> Linear(in_features=3116, out_features=50, bias=True)\n","Saved model to: ./saved_disassembled_models/VGG16_tinyimagenet_disassembled_seed12_150_199.pth\n","VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Conv2d(61, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace=True)\n","    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (7): Conv2d(64, 121, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): BatchNorm2d(121, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(121, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU(inplace=True)\n","    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (14): Conv2d(120, 233, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): BatchNorm2d(233, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (16): ReLU(inplace=True)\n","    (17): Conv2d(233, 236, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): BatchNorm2d(236, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (19): ReLU(inplace=True)\n","    (20): Conv2d(236, 253, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (21): BatchNorm2d(253, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(253, 497, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): BatchNorm2d(497, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (26): ReLU(inplace=True)\n","    (27): Conv2d(497, 495, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (28): BatchNorm2d(495, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (29): ReLU(inplace=True)\n","    (30): Conv2d(495, 507, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (31): BatchNorm2d(507, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (32): ReLU(inplace=True)\n","    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (34): Conv2d(507, 481, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (35): BatchNorm2d(481, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (36): ReLU(inplace=True)\n","    (37): Conv2d(481, 493, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (38): BatchNorm2d(493, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (39): ReLU(inplace=True)\n","    (40): Conv2d(493, 135, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (41): BatchNorm2d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (42): ReLU(inplace=True)\n","    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=540, out_features=2888, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=2888, out_features=3116, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=3116, out_features=50, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"code","source":["\n","source_test_dir = '/content/tiny_imagenet_images/saved_datasets/tiny_imagenet_images/val'\n","target_test_dir = '/content/tiny_imagenet_images/saved_datasets/tiny_imagenet_images_subset_123/val_150_199'\n","\n","filter_selected_classes(\n","    source_dir=source_test_dir,\n","    target_dir=target_test_dir,\n","    class_indices=range(150,200)\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RZMfMpWz3X89","executionInfo":{"status":"ok","timestamp":1747048511126,"user_tz":-60,"elapsed":222,"user":{"displayName":"Ajayesh Saini","userId":"13319741441885932090"}},"outputId":"8a3f4b5c-3e1f-410d-a9f3-2bc305b3318a"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["Copied: n04259630\n","Copied: n04265275\n","Copied: n04275548\n","Copied: n04285008\n","Copied: n04311004\n","Copied: n04328186\n","Copied: n04356056\n","Copied: n04366367\n","Copied: n04371430\n","Copied: n04376876\n","Copied: n04398044\n","Copied: n04399382\n","Copied: n04417672\n","Copied: n04456115\n","Copied: n04465501\n","Copied: n04486054\n","Copied: n04487081\n","Copied: n04501370\n","Copied: n04507155\n","Copied: n04532106\n","Copied: n04532670\n","Copied: n04540053\n","Copied: n04560804\n","Copied: n04562935\n","Copied: n04596742\n","Copied: n04597913\n","Copied: n06596364\n","Copied: n07579787\n","Copied: n07583066\n","Copied: n07614500\n","Copied: n07615774\n","Copied: n07695742\n","Copied: n07711569\n","Copied: n07715103\n","Copied: n07720875\n","Copied: n07734744\n","Copied: n07747607\n","Copied: n07749582\n","Copied: n07753592\n","Copied: n07768694\n","Copied: n07871810\n","Copied: n07873807\n","Copied: n07875152\n","Copied: n07920052\n","Copied: n09193705\n","Copied: n09246464\n","Copied: n09256479\n","Copied: n09332890\n","Copied: n09428293\n","Copied: n12267677\n"]}]},{"cell_type":"code","source":["!python -m engines.test \\\n","  --model_name 'vgg16' \\\n","  --data_name tiny-imagenet \\\n","  --num_classes 200 \\\n","  --model_path \"./saved_disassembled_models/VGG16_tinyimagenet_disassembled_seed12_150_199.pth\" \\\n","  --data_dir \"/content/tiny_imagenet_images/saved_datasets/tiny_imagenet_images_subset_123/val_150_199\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iGoKN1xC4XIz","executionInfo":{"status":"ok","timestamp":1747048534744,"user_tz":-60,"elapsed":3929,"user":{"displayName":"Ajayesh Saini","userId":"13319741441885932090"}},"outputId":"17989075-a022-410a-abdb-2c01e1018c9a"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["--------------------------------------------------\n","TEST ON: cuda\n","MODEL PATH: ./saved_disassembled_models/VGG16_tinyimagenet_disassembled_seed12_150_199.pth\n","DATA PATH: /content/tiny_imagenet_images/saved_datasets/tiny_imagenet_images_subset_123/val_150_199\n","--------------------------------------------------\n","--------------------------------------------------\n","DATA PATH: /content/tiny_imagenet_images/saved_datasets/tiny_imagenet_images_subset_123/val_150_199\n","DATA NAME: tiny-imagenet \t|\tDATA TYPE: test\n","--------------------------------------------------\n","[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n","[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n","[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n","[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n","[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n","[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n","[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n","FLOPs = 1.137006344G\n","Params = 22.785017M\n","--------------------------------------------------\n","0: 26.00\n","1:  0.00\n","2: 26.00\n","3: 56.00\n","4: 72.00\n","5: 22.00\n","6: 12.00\n","7: 74.00\n","8: 36.00\n","9:  0.00\n","10: 12.00\n","11:  6.00\n","12: 40.00\n","13: 20.00\n","14: 44.00\n","15: 28.00\n","16: 64.00\n","17:  4.00\n","18: 42.00\n","19: 12.00\n","20: 26.00\n","21: 68.00\n","22:  0.00\n","23: 42.00\n","24: 32.00\n","25: 42.00\n","26: 38.00\n","27: 14.00\n","28: 72.00\n","29: 18.00\n","30:  2.00\n","31: 30.00\n","32:  4.00\n","33: 72.00\n","34: 36.00\n","35: 50.00\n","36: 60.00\n","37: 80.00\n","38: 70.00\n","39: 34.00\n","40: 16.00\n","41: 90.00\n","42: 44.00\n","43:  0.00\n","44: 78.00\n","45: 44.00\n","46: 82.00\n","47: 48.00\n","48: 60.00\n","49: 24.00\n","AVG: 37.44000002441406\n"]}]},{"cell_type":"code","source":["!python -m engines.test \\\n","  --model_name 'vgg16' \\\n","  --data_name 'tiny-imagenet' \\\n","  --num_classes 200 \\\n","  --model_path \"./saved_models/VGG16_tinyimagenet_seed123.pth\" \\\n","  --data_dir \"/content/tiny_imagenet_images/saved_datasets/tiny_imagenet_images/val\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w2RvY1476OzV","executionInfo":{"status":"ok","timestamp":1747046498343,"user_tz":-60,"elapsed":9430,"user":{"displayName":"Ajayesh Saini","userId":"13319741441885932090"}},"outputId":"bb2bfde5-a638-41d3-ba07-534d58684ffc"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["--------------------------------------------------\n","TEST ON: cuda\n","MODEL PATH: ./saved_models/VGG16_tinyimagenet_seed123.pth\n","DATA PATH: /content/tiny_imagenet_images/saved_datasets/tiny_imagenet_images/val\n","--------------------------------------------------\n","--------------------------------------------------\n","LOAD MODEL: vgg16\n","NUM CLASSES: 200\n","--------------------------------------------------\n","--------------------------------------------------\n","DATA PATH: /content/tiny_imagenet_images/saved_datasets/tiny_imagenet_images/val\n","DATA NAME: tiny-imagenet \t|\tDATA TYPE: test\n","--------------------------------------------------\n","[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n","[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n","[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n","[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n","[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n","[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n","[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n","FLOPs = 1.28319488G\n","Params = 40.716552M\n","Test[19/40]  Loss[2.5861e+00]  Acc@1[ 57.23]  Acc@5[ 57.23]\n","Test[39/40]  Loss[2.6277e+00]  Acc@1[ 57.27]  Acc@5[ 57.27]\n","--------------------------------------------------\n","0: 86.00\n","1: 78.00\n","2: 64.00\n","3: 58.00\n","4: 64.00\n","5: 54.00\n","6: 76.00\n","7: 48.00\n","8: 72.00\n","9: 52.00\n","10: 52.00\n","11: 74.00\n","12: 70.00\n","13: 74.00\n","14: 76.00\n","15: 52.00\n","16: 42.00\n","17: 56.00\n","18: 54.00\n","19: 60.00\n","20: 82.00\n","21: 70.00\n","22: 78.00\n","23: 80.00\n","24: 42.00\n","25: 76.00\n","26: 56.00\n","27: 32.00\n","28: 44.00\n","29: 48.00\n","30: 46.00\n","31: 64.00\n","32: 38.00\n","33: 38.00\n","34: 74.00\n","35: 62.00\n","36: 76.00\n","37: 64.00\n","38: 62.00\n","39: 58.00\n","40: 34.00\n","41: 54.00\n","42: 46.00\n","43: 60.00\n","44: 88.00\n","45: 80.00\n","46: 54.00\n","47: 52.00\n","48: 32.00\n","49: 50.00\n","50: 80.00\n","51: 56.00\n","52: 76.00\n","53: 64.00\n","54: 58.00\n","55: 66.00\n","56: 46.00\n","57: 72.00\n","58: 68.00\n","59: 50.00\n","60: 66.00\n","61: 68.00\n","62: 34.00\n","63: 62.00\n","64: 36.00\n","65: 44.00\n","66: 66.00\n","67: 30.00\n","68: 58.00\n","69: 36.00\n","70: 56.00\n","71: 80.00\n","72: 38.00\n","73: 54.00\n","74: 72.00\n","75: 54.00\n","76: 60.00\n","77: 36.00\n","78: 82.00\n","79: 30.00\n","80: 30.00\n","81: 88.00\n","82: 68.00\n","83: 52.00\n","84: 56.00\n","85: 44.00\n","86: 52.00\n","87: 60.00\n","88: 28.00\n","89: 52.00\n","90: 72.00\n","91: 62.00\n","92: 44.00\n","93: 60.00\n","94: 66.00\n","95: 66.00\n","96: 48.00\n","97: 54.00\n","98: 62.00\n","99: 38.00\n","100: 32.00\n","101: 66.00\n","102: 54.00\n","103: 76.00\n","104: 38.00\n","105: 46.00\n","106: 40.00\n","107: 70.00\n","108: 82.00\n","109: 64.00\n","110: 56.00\n","111: 64.00\n","112: 48.00\n","113: 46.00\n","114: 42.00\n","115: 78.00\n","116: 44.00\n","117: 54.00\n","118: 80.00\n","119: 40.00\n","120: 42.00\n","121: 62.00\n","122: 36.00\n","123: 52.00\n","124: 82.00\n","125: 40.00\n","126: 72.00\n","127: 64.00\n","128: 50.00\n","129: 68.00\n","130: 50.00\n","131: 24.00\n","132: 20.00\n","133: 84.00\n","134: 58.00\n","135: 28.00\n","136: 50.00\n","137: 38.00\n","138: 22.00\n","139: 30.00\n","140: 68.00\n","141: 40.00\n","142: 40.00\n","143: 82.00\n","144: 54.00\n","145: 92.00\n","146: 72.00\n","147: 52.00\n","148: 60.00\n","149: 68.00\n","150: 54.00\n","151: 48.00\n","152: 60.00\n","153: 76.00\n","154: 66.00\n","155: 68.00\n","156: 48.00\n","157: 56.00\n","158: 30.00\n","159: 24.00\n","160: 48.00\n","161: 64.00\n","162: 68.00\n","163: 52.00\n","164: 70.00\n","165: 86.00\n","166: 86.00\n","167: 56.00\n","168: 32.00\n","169: 68.00\n","170: 74.00\n","171: 74.00\n","172: 26.00\n","173: 78.00\n","174: 54.00\n","175: 14.00\n","176: 78.00\n","177: 36.00\n","178: 60.00\n","179: 50.00\n","180: 42.00\n","181: 60.00\n","182: 34.00\n","183: 54.00\n","184: 72.00\n","185: 64.00\n","186: 66.00\n","187: 72.00\n","188: 58.00\n","189: 74.00\n","190: 58.00\n","191: 80.00\n","192: 72.00\n","193: 84.00\n","194: 64.00\n","195: 54.00\n","196: 68.00\n","197: 44.00\n","198: 52.00\n","199: 56.00\n","AVG: 57.27\n"]}]}]}